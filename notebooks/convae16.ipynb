{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59bb04c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ConvAutoencoder16.__init__() got an unexpected keyword argument 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 3. Load your checkpoint\u001b[39;00m\n\u001b[0;32m     25\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m project_root \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts/autoencoder/checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvAE16_2025-06-16_12-02-51.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mConvAutoencoder16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# set to inference mode\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 4. Pick a small batch from validation (or full dataset) for testing\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\CSIC\\deep-learning-wall-tomography\\models\\autoencoder\\autoencoder_base.py:193\u001b[0m, in \u001b[0;36mAutoencoderBase.load\u001b[1;34m(cls, path, device)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mLoad model checkpoint. Subclasses should override to restore optimizer, args, etc.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(path, map_location\u001b[38;5;241m=\u001b[39mdevice \u001b[38;5;129;01mor\u001b[39;00m DEVICE)\n\u001b[1;32m--> 193\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    195\u001b[0m model\u001b[38;5;241m.\u001b[39mepochs_trained \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs_trained\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: ConvAutoencoder16.__init__() got an unexpected keyword argument 'model_name'"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = Path(__file__).resolve().parent.parent if '__file__' in globals() else Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from models.autoencoder.dataset_autoencoder import DatasetAutoencoder\n",
    "from models.autoencoder.architectures.conv_autoencoder16 import ConvAutoencoder16\n",
    "\n",
    "# 2. Load the same dataset you trained on\n",
    "dataset = DatasetAutoencoder(\n",
    "    path=Path(\"data/waves\"),    # or wherever your raw data lives\n",
    "    reduction=\"\",               # match what you used in training\n",
    "    n=0,\n",
    "    save=False,                 # no need to re-cache here\n",
    "    force_reload=False\n",
    ")\n",
    "\n",
    "# 3. Load your checkpoint\n",
    "ckpt = project_root / Path(\"artifacts/autoencoder/checkpoints\") / \"ConvAE16_2025-06-16_12-02-51.pt\"\n",
    "model = ConvAutoencoder16.load(ckpt)\n",
    "model.eval()  # set to inference mode\n",
    "\n",
    "# 4. Pick a small batch from validation (or full dataset) for testing\n",
    "loader = DataLoader(dataset, batch_size=6, shuffle=True)\n",
    "batch = next(iter(loader))            # shape [6, length]\n",
    "batch_in = batch.unsqueeze(1).to(model.device)   # → [6,1,length]\n",
    "\n",
    "# 5. Run the autoencoder\n",
    "with torch.no_grad():\n",
    "    recon = model(batch_in)           # → [6, length]\n",
    "recon = recon.cpu()                   # bring back to CPU\n",
    "\n",
    "# 6. Plot originals vs reconstructions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(batch[i].numpy(),   label=\"Original\")\n",
    "    ax.plot(recon[i].numpy(),   label=\"Reconstruction\")\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.legend(fontsize=\"small\")\n",
    "fig.suptitle(\"ConvAE16 Reconstructions (6 random waves)\")\n",
    "fig.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
